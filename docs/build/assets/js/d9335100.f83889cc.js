"use strict";(self.webpackChunkpmdaemon_docs=self.webpackChunkpmdaemon_docs||[]).push([[7418],{1883:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"advanced/performance-tuning","title":"Performance Tuning","description":"This guide covers optimization strategies for PMDaemon to achieve maximum performance in production environments. Learn how to tune system resources, optimize process configurations, and scale effectively.","source":"@site/docs/advanced/performance-tuning.md","sourceDirName":"advanced","slug":"/advanced/performance-tuning","permalink":"/pmdaemon/docs/advanced/performance-tuning","draft":false,"unlisted":false,"editUrl":"https://github.com/entrepeneur4lyf/pmdaemon/tree/main/docs/docs/advanced/performance-tuning.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Integration Examples","permalink":"/pmdaemon/docs/examples/integration-examples"},"next":{"title":"Security","permalink":"/pmdaemon/docs/advanced/security"}}');var s=r(4848),t=r(8453);const o={},a="Performance Tuning",c={},l=[{value:"System-Level Optimizations",id:"system-level-optimizations",level:2},{value:"Operating System Tuning",id:"operating-system-tuning",level:3},{value:"File Descriptor Limits",id:"file-descriptor-limits",level:4},{value:"Memory Management",id:"memory-management",level:4},{value:"Network Optimization",id:"network-optimization",level:4},{value:"PMDaemon Configuration",id:"pmdaemon-configuration",level:3},{value:"Monitoring Intervals",id:"monitoring-intervals",level:4},{value:"Log Management",id:"log-management",level:4},{value:"Process-Level Optimizations",id:"process-level-optimizations",level:2},{value:"Instance Scaling Strategies",id:"instance-scaling-strategies",level:3},{value:"CPU-Based Scaling",id:"cpu-based-scaling",level:4},{value:"Memory-Aware Scaling",id:"memory-aware-scaling",level:4},{value:"Port Management Optimization",id:"port-management-optimization",level:3},{value:"Efficient Port Allocation",id:"efficient-port-allocation",level:4},{value:"Load Balancer Integration",id:"load-balancer-integration",level:4},{value:"Application-Specific Optimizations",id:"application-specific-optimizations",level:2},{value:"Node.js Applications",id:"nodejs-applications",level:3},{value:"Memory and CPU Tuning",id:"memory-and-cpu-tuning",level:4},{value:"Cluster Mode Optimization",id:"cluster-mode-optimization",level:4},{value:"Python Applications",id:"python-applications",level:3},{value:"WSGI Server Optimization",id:"wsgi-server-optimization",level:4},{value:"Async Python Applications",id:"async-python-applications",level:4},{value:"Health Check Optimization",id:"health-check-optimization",level:2},{value:"Efficient Health Checks",id:"efficient-health-checks",level:3},{value:"Lightweight Health Endpoints",id:"lightweight-health-endpoints",level:3},{value:"Monitoring and Metrics Optimization",id:"monitoring-and-metrics-optimization",level:2},{value:"Efficient Metrics Collection",id:"efficient-metrics-collection",level:3},{value:"Custom Metrics Integration",id:"custom-metrics-integration",level:3},{value:"Database and External Service Optimization",id:"database-and-external-service-optimization",level:2},{value:"Connection Pooling",id:"connection-pooling",level:3},{value:"Redis Optimization",id:"redis-optimization",level:3},{value:"Performance Monitoring",id:"performance-monitoring",level:2},{value:"Benchmarking Setup",id:"benchmarking-setup",level:3},{value:"Performance Metrics Dashboard",id:"performance-metrics-dashboard",level:3},{value:"Best Practices Summary",id:"best-practices-summary",level:2},{value:"1. Right-Size Your Instances",id:"1-right-size-your-instances",level:3},{value:"2. Optimize Health Checks",id:"2-optimize-health-checks",level:3},{value:"3. Use Efficient Logging",id:"3-use-efficient-logging",level:3},{value:"4. Monitor Resource Usage",id:"4-monitor-resource-usage",level:3},{value:"5. Optimize for Your Workload",id:"5-optimize-for-your-workload",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"performance-tuning",children:"Performance Tuning"})}),"\n",(0,s.jsx)(n.p,{children:"This guide covers optimization strategies for PMDaemon to achieve maximum performance in production environments. Learn how to tune system resources, optimize process configurations, and scale effectively."}),"\n",(0,s.jsx)(n.h2,{id:"system-level-optimizations",children:"System-Level Optimizations"}),"\n",(0,s.jsx)(n.h3,{id:"operating-system-tuning",children:"Operating System Tuning"}),"\n",(0,s.jsx)(n.h4,{id:"file-descriptor-limits",children:"File Descriptor Limits"}),"\n",(0,s.jsx)(n.p,{children:"PMDaemon manages multiple processes and connections, requiring adequate file descriptor limits:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Check current limits\r\nulimit -n\r\n\r\n# Increase for current session\r\nulimit -n 65536\r\n\r\n# Permanent increase (add to /etc/security/limits.conf)\r\necho "* soft nofile 65536" | sudo tee -a /etc/security/limits.conf\r\necho "* hard nofile 65536" | sudo tee -a /etc/security/limits.conf\r\n\r\n# For systemd services\r\nsudo mkdir -p /etc/systemd/system/pmdaemon.service.d\r\necho "[Service]" | sudo tee /etc/systemd/system/pmdaemon.service.d/limits.conf\r\necho "LimitNOFILE=65536" | sudo tee -a /etc/systemd/system/pmdaemon.service.d/limits.conf\n'})}),"\n",(0,s.jsx)(n.h4,{id:"memory-management",children:"Memory Management"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Optimize memory overcommit\r\necho 1 | sudo tee /proc/sys/vm/overcommit_memory\r\n\r\n# Adjust swappiness for better performance\r\necho 10 | sudo tee /proc/sys/vm/swappiness\r\n\r\n# Increase shared memory limits\r\necho "kernel.shmmax = 68719476736" | sudo tee -a /etc/sysctl.conf\r\necho "kernel.shmall = 4294967296" | sudo tee -a /etc/sysctl.conf\n'})}),"\n",(0,s.jsx)(n.h4,{id:"network-optimization",children:"Network Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Increase network buffer sizes\r\necho "net.core.rmem_max = 16777216" | sudo tee -a /etc/sysctl.conf\r\necho "net.core.wmem_max = 16777216" | sudo tee -a /etc/sysctl.conf\r\necho "net.ipv4.tcp_rmem = 4096 87380 16777216" | sudo tee -a /etc/sysctl.conf\r\necho "net.ipv4.tcp_wmem = 4096 65536 16777216" | sudo tee -a /etc/sysctl.conf\r\n\r\n# Apply changes\r\nsudo sysctl -p\n'})}),"\n",(0,s.jsx)(n.h3,{id:"pmdaemon-configuration",children:"PMDaemon Configuration"}),"\n",(0,s.jsx)(n.h4,{id:"monitoring-intervals",children:"Monitoring Intervals"}),"\n",(0,s.jsx)(n.p,{children:"Optimize monitoring frequency based on your needs:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# High-frequency monitoring (development)\r\npmdaemon monit --interval 1s\r\n\r\n# Balanced monitoring (production)\r\npmdaemon monit --interval 5s\r\n\r\n# Low-overhead monitoring (resource-constrained)\r\npmdaemon monit --interval 30s\n"})}),"\n",(0,s.jsx)(n.h4,{id:"log-management",children:"Log Management"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "name": "optimized-service",\r\n  "script": "node",\r\n  "args": ["server.js"],\r\n  "log": {\r\n    "out_file": "/dev/null",\r\n    "error_file": "/var/log/app/error.log",\r\n    "max_log_size": "50M",\r\n    "max_log_files": 3,\r\n    "compress_logs": true\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"process-level-optimizations",children:"Process-Level Optimizations"}),"\n",(0,s.jsx)(n.h3,{id:"instance-scaling-strategies",children:"Instance Scaling Strategies"}),"\n",(0,s.jsx)(n.h4,{id:"cpu-based-scaling",children:"CPU-Based Scaling"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Get CPU core count\r\nCPU_CORES=$(nproc)\r\n\r\n# Scale based on workload type\r\n# CPU-intensive: 1 instance per core\r\npmdaemon start "node cpu-intensive.js" --name cpu-app --instances $CPU_CORES\r\n\r\n# I/O-intensive: 2x cores\r\npmdaemon start "node io-intensive.js" --name io-app --instances $((CPU_CORES * 2))\r\n\r\n# Mixed workload: 1.5x cores\r\npmdaemon start "node mixed-app.js" --name mixed-app --instances $((CPU_CORES * 3 / 2))\n'})}),"\n",(0,s.jsx)(n.h4,{id:"memory-aware-scaling",children:"Memory-Aware Scaling"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Calculate optimal instances based on memory\r\nTOTAL_MEMORY=$(free -m | awk 'NR==2{print $2}')\r\nMEMORY_PER_INSTANCE=512  # MB\r\nOPTIMAL_INSTANCES=$((TOTAL_MEMORY / MEMORY_PER_INSTANCE / 2))  # Leave 50% for system\r\n\r\npmdaemon start \"node server.js\" --name web-app \\\r\n  --instances $OPTIMAL_INSTANCES \\\r\n  --max-memory ${MEMORY_PER_INSTANCE}M\n"})}),"\n",(0,s.jsx)(n.h3,{id:"port-management-optimization",children:"Port Management Optimization"}),"\n",(0,s.jsx)(n.h4,{id:"efficient-port-allocation",children:"Efficient Port Allocation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "apps": [\r\n    {\r\n      "name": "web-cluster",\r\n      "script": "node",\r\n      "args": ["server.js"],\r\n      "instances": 8,\r\n      "port": "auto:8000-8100",\r\n      "env": {\r\n        "UV_THREADPOOL_SIZE": "4"\r\n      }\r\n    }\r\n  ]\r\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"load-balancer-integration",children:"Load Balancer Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-nginx",children:'# nginx.conf - Optimized upstream configuration\r\nupstream app_cluster {\r\n    least_conn;\r\n    server localhost:8000 weight=1 max_fails=3 fail_timeout=30s;\r\n    server localhost:8001 weight=1 max_fails=3 fail_timeout=30s;\r\n    server localhost:8002 weight=1 max_fails=3 fail_timeout=30s;\r\n    server localhost:8003 weight=1 max_fails=3 fail_timeout=30s;\r\n    keepalive 32;\r\n}\r\n\r\nserver {\r\n    listen 80;\r\n    \r\n    location / {\r\n        proxy_pass http://app_cluster;\r\n        proxy_http_version 1.1;\r\n        proxy_set_header Connection "";\r\n        proxy_set_header Host $host;\r\n        proxy_set_header X-Real-IP $remote_addr;\r\n        proxy_connect_timeout 5s;\r\n        proxy_send_timeout 60s;\r\n        proxy_read_timeout 60s;\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"application-specific-optimizations",children:"Application-Specific Optimizations"}),"\n",(0,s.jsx)(n.h3,{id:"nodejs-applications",children:"Node.js Applications"}),"\n",(0,s.jsx)(n.h4,{id:"memory-and-cpu-tuning",children:"Memory and CPU Tuning"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "name": "nodejs-optimized",\r\n  "script": "node",\r\n  "args": [\r\n    "--max-old-space-size=1024",\r\n    "--max-new-space-size=256",\r\n    "--optimize-for-size",\r\n    "server.js"\r\n  ],\r\n  "instances": 4,\r\n  "env": {\r\n    "NODE_ENV": "production",\r\n    "UV_THREADPOOL_SIZE": "16",\r\n    "NODE_OPTIONS": "--max-old-space-size=1024"\r\n  },\r\n  "max_memory_restart": "1200M"\r\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"cluster-mode-optimization",children:"Cluster Mode Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// server.js - Optimized cluster setup\r\nconst cluster = require('cluster');\r\nconst numCPUs = require('os').cpus().length;\r\n\r\nif (cluster.isMaster) {\r\n  // Master process\r\n  console.log(`Master ${process.pid} is running`);\r\n  \r\n  // Fork workers\r\n  for (let i = 0; i < numCPUs; i++) {\r\n    cluster.fork();\r\n  }\r\n  \r\n  cluster.on('exit', (worker, code, signal) => {\r\n    console.log(`Worker ${worker.process.pid} died`);\r\n    cluster.fork(); // Restart worker\r\n  });\r\n} else {\r\n  // Worker process\r\n  const express = require('express');\r\n  const app = express();\r\n  \r\n  // Optimize Express\r\n  app.set('trust proxy', true);\r\n  app.disable('x-powered-by');\r\n  \r\n  // Connection pooling\r\n  const pool = require('generic-pool');\r\n  \r\n  app.listen(process.env.PORT || 3000, () => {\r\n    console.log(`Worker ${process.pid} started`);\r\n  });\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"python-applications",children:"Python Applications"}),"\n",(0,s.jsx)(n.h4,{id:"wsgi-server-optimization",children:"WSGI Server Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "name": "python-optimized",\r\n  "script": "gunicorn",\r\n  "args": [\r\n    "--workers", "4",\r\n    "--worker-class", "gevent",\r\n    "--worker-connections", "1000",\r\n    "--max-requests", "1000",\r\n    "--max-requests-jitter", "100",\r\n    "--preload",\r\n    "--bind", "0.0.0.0:8000",\r\n    "app:application"\r\n  ],\r\n  "env": {\r\n    "PYTHONOPTIMIZE": "1",\r\n    "PYTHONUNBUFFERED": "1"\r\n  },\r\n  "max_memory_restart": "512M"\r\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"async-python-applications",children:"Async Python Applications"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "name": "fastapi-optimized",\r\n  "script": "uvicorn",\r\n  "args": [\r\n    "main:app",\r\n    "--host", "0.0.0.0",\r\n    "--port", "8000",\r\n    "--workers", "4",\r\n    "--loop", "uvloop",\r\n    "--http", "httptools"\r\n  ],\r\n  "env": {\r\n    "PYTHONPATH": "/app",\r\n    "PYTHONOPTIMIZE": "2"\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"health-check-optimization",children:"Health Check Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"efficient-health-checks",children:"Efficient Health Checks"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "name": "optimized-health-checks",\r\n  "script": "node",\r\n  "args": ["server.js"],\r\n  "health_check": {\r\n    "check_type": "http",\r\n    "url": "http://localhost:3000/health",\r\n    "timeout": 5,\r\n    "interval": 30,\r\n    "retries": 2\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"lightweight-health-endpoints",children:"Lightweight Health Endpoints"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Optimized health check endpoint\r\napp.get('/health', (req, res) => {\r\n  // Quick checks only\r\n  const health = {\r\n    status: 'healthy',\r\n    timestamp: Date.now(),\r\n    uptime: process.uptime(),\r\n    memory: process.memoryUsage().rss\r\n  };\r\n  \r\n  res.json(health);\r\n});\r\n\r\n// Detailed health check (separate endpoint)\r\napp.get('/health/detailed', async (req, res) => {\r\n  try {\r\n    // More comprehensive checks\r\n    await checkDatabase();\r\n    await checkRedis();\r\n    await checkExternalServices();\r\n    \r\n    res.json({ status: 'healthy', checks: 'all_passed' });\r\n  } catch (error) {\r\n    res.status(503).json({ status: 'unhealthy', error: error.message });\r\n  }\r\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"monitoring-and-metrics-optimization",children:"Monitoring and Metrics Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"efficient-metrics-collection",children:"Efficient Metrics Collection"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Reduce monitoring overhead\r\nexport PMDAEMON_METRICS_INTERVAL=10s\r\nexport PMDAEMON_METRICS_BUFFER_SIZE=1000\r\n\r\n# Start with optimized monitoring\r\npmdaemon start "node server.js" --name web-app\n'})}),"\n",(0,s.jsx)(n.h3,{id:"custom-metrics-integration",children:"Custom Metrics Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Prometheus metrics integration\r\nconst prometheus = require('prom-client');\r\n\r\n// Create custom metrics\r\nconst httpRequestDuration = new prometheus.Histogram({\r\n  name: 'http_request_duration_seconds',\r\n  help: 'Duration of HTTP requests in seconds',\r\n  labelNames: ['method', 'route', 'status_code']\r\n});\r\n\r\n// Middleware for metrics collection\r\napp.use((req, res, next) => {\r\n  const start = Date.now();\r\n  \r\n  res.on('finish', () => {\r\n    const duration = (Date.now() - start) / 1000;\r\n    httpRequestDuration\r\n      .labels(req.method, req.route?.path || req.path, res.statusCode)\r\n      .observe(duration);\r\n  });\r\n  \r\n  next();\r\n});\r\n\r\n// Metrics endpoint\r\napp.get('/metrics', (req, res) => {\r\n  res.set('Content-Type', prometheus.register.contentType);\r\n  res.end(prometheus.register.metrics());\r\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"database-and-external-service-optimization",children:"Database and External Service Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"connection-pooling",children:"Connection Pooling"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Optimized database connection pooling\r\nconst { Pool } = require('pg');\r\n\r\nconst pool = new Pool({\r\n  host: process.env.DB_HOST,\r\n  database: process.env.DB_NAME,\r\n  user: process.env.DB_USER,\r\n  password: process.env.DB_PASSWORD,\r\n  port: process.env.DB_PORT,\r\n  max: 20, // Maximum connections\r\n  min: 5,  // Minimum connections\r\n  idleTimeoutMillis: 30000,\r\n  connectionTimeoutMillis: 2000,\r\n  maxUses: 7500, // Close connection after 7500 uses\r\n});\r\n\r\n// Connection health check\r\nsetInterval(async () => {\r\n  try {\r\n    await pool.query('SELECT 1');\r\n  } catch (error) {\r\n    console.error('Database health check failed:', error);\r\n  }\r\n}, 30000);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"redis-optimization",children:"Redis Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Optimized Redis configuration\r\nconst Redis = require('ioredis');\r\n\r\nconst redis = new Redis({\r\n  host: process.env.REDIS_HOST,\r\n  port: process.env.REDIS_PORT,\r\n  maxRetriesPerRequest: 3,\r\n  retryDelayOnFailover: 100,\r\n  enableReadyCheck: false,\r\n  maxLoadingTimeout: 1000,\r\n  lazyConnect: true,\r\n  keepAlive: 30000,\r\n  family: 4,\r\n  connectTimeout: 10000,\r\n  commandTimeout: 5000,\r\n});\r\n\r\n// Connection pooling for Redis\r\nconst cluster = new Redis.Cluster([\r\n  { host: 'redis-1', port: 6379 },\r\n  { host: 'redis-2', port: 6379 },\r\n  { host: 'redis-3', port: 6379 }\r\n], {\r\n  enableOfflineQueue: false,\r\n  redisOptions: {\r\n    password: process.env.REDIS_PASSWORD\r\n  }\r\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-monitoring",children:"Performance Monitoring"}),"\n",(0,s.jsx)(n.h3,{id:"benchmarking-setup",children:"Benchmarking Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\r\n# benchmark.sh - Performance testing script\r\n\r\necho "\ud83d\ude80 Starting performance benchmark..."\r\n\r\n# Start optimized configuration\r\npmdaemon --config ecosystem.optimized.json start\r\n\r\n# Wait for services to be ready\r\nsleep 30\r\n\r\n# Run load tests\r\necho "\ud83d\udcca Running load tests..."\r\n\r\n# HTTP load test\r\nab -n 10000 -c 100 http://localhost:3000/ > results/ab-results.txt\r\n\r\n# WebSocket load test\r\nnode websocket-load-test.js > results/ws-results.txt\r\n\r\n# Database load test\r\npgbench -c 10 -j 2 -t 1000 myapp_db > results/db-results.txt\r\n\r\necho "\u2705 Benchmark complete. Results in results/ directory."\n'})}),"\n",(0,s.jsx)(n.h3,{id:"performance-metrics-dashboard",children:"Performance Metrics Dashboard"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// performance-dashboard.js\r\nconst PMDaemonClient = require('./pmdaemon-client');\r\n\r\nclass PerformanceDashboard {\r\n  constructor() {\r\n    this.client = new PMDaemonClient();\r\n    this.metrics = {\r\n      requests_per_second: 0,\r\n      average_response_time: 0,\r\n      error_rate: 0,\r\n      cpu_usage: 0,\r\n      memory_usage: 0\r\n    };\r\n  }\r\n\r\n  async collectMetrics() {\r\n    const processes = await this.client.listProcesses();\r\n    const systemMetrics = await this.client.getSystemMetrics();\r\n    \r\n    // Calculate aggregate metrics\r\n    this.metrics.cpu_usage = systemMetrics.cpu.usage;\r\n    this.metrics.memory_usage = systemMetrics.memory.usage_percent;\r\n    \r\n    // Process-specific metrics\r\n    processes.processes.forEach(proc => {\r\n      console.log(`${proc.name}: CPU ${proc.cpu}%, Memory ${proc.memory}MB`);\r\n    });\r\n    \r\n    return this.metrics;\r\n  }\r\n\r\n  async optimizeBasedOnMetrics() {\r\n    const metrics = await this.collectMetrics();\r\n    \r\n    if (metrics.cpu_usage > 80) {\r\n      console.log('\ud83d\udd25 High CPU usage detected, scaling up...');\r\n      // Scale up instances\r\n    }\r\n    \r\n    if (metrics.memory_usage > 85) {\r\n      console.log('\ud83d\udcbe High memory usage detected, optimizing...');\r\n      // Restart memory-heavy processes\r\n    }\r\n    \r\n    if (metrics.error_rate > 5) {\r\n      console.log('\u274c High error rate detected, investigating...');\r\n      // Check logs and restart failing processes\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"best-practices-summary",children:"Best Practices Summary"}),"\n",(0,s.jsx)(n.h3,{id:"1-right-size-your-instances",children:"1. Right-Size Your Instances"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# CPU-bound applications\r\npmdaemon start "cpu-app" --instances $(nproc)\r\n\r\n# I/O-bound applications  \r\npmdaemon start "io-app" --instances $(($(nproc) * 2))\r\n\r\n# Memory-bound applications\r\npmdaemon start "memory-app" --instances 2 --max-memory 2G\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-optimize-health-checks",children:"2. Optimize Health Checks"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Frequent but lightweight health checks\r\npmdaemon start "node server.js" --name web-api \\\r\n  --health-check-url http://localhost:3000/ping \\\r\n  --health-check-timeout 2s \\\r\n  --health-check-interval 15s\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-use-efficient-logging",children:"3. Use Efficient Logging"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Structured logging with rotation\r\npmdaemon start "node server.js" --name web-api \\\r\n  --out-file /var/log/app/web-api.json \\\r\n  --error-file /var/log/app/web-api-error.log\n'})}),"\n",(0,s.jsx)(n.h3,{id:"4-monitor-resource-usage",children:"4. Monitor Resource Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Set appropriate limits\r\npmdaemon start "node server.js" --name web-api \\\r\n  --max-memory 512M \\\r\n  --max-restarts 5 \\\r\n  --min-uptime 10s\n'})}),"\n",(0,s.jsx)(n.h3,{id:"5-optimize-for-your-workload",children:"5. Optimize for Your Workload"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Web servers: Focus on concurrency\r\npmdaemon start "node web.js" --instances 8 --port auto:3000-3100\r\n\r\n# Workers: Focus on throughput\r\npmdaemon start "python worker.py" --instances 4 --max-memory 1G\r\n\r\n# APIs: Balance both\r\npmdaemon start "node api.js" --instances 6 --port 8000-8005 --max-memory 512M\n'})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/pmdaemon/docs/advanced/security",children:"Security"})})," - Security optimization and hardening"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/pmdaemon/docs/advanced/clustering",children:"Clustering"})})," - Advanced clustering strategies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/pmdaemon/docs/advanced/logging",children:"Logging"})})," - Optimized logging configuration"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/pmdaemon/docs/advanced/troubleshooting",children:"Troubleshooting"})})," - Performance issue diagnosis"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var i=r(6540);const s={},t=i.createContext(s);function o(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);